{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b193403",
   "metadata": {},
   "source": [
    "# Introduction - Titanic Linear Regression\n",
    "\n",
    "Name: Gabriel Richards / gjrich\n",
    "\n",
    "Date: 5 Apr 2025\n",
    "\n",
    "This lab uses the Titanic dataset to review regression modeling techniques. Previous work focused on classification (predicting survival), but we'll now predict the fare passengers paid for their journey. We'll review how  passenger attributes like age, family size, and other features correlate with ticket pricing. We'll also build multiple regression models including Linear Regression, Ridge, Elastic Net, and Polynomial Regression, and evaluate their performance using R², RMSE, and MAE to determine which features and models best predict passenger fares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4be2e3",
   "metadata": {},
   "source": [
    "## Python Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03923e",
   "metadata": {},
   "source": [
    "## Section 1. Import and Inspect the Data\n",
    "\n",
    "Load the Titanic dataset and confirm it’s structured correctly.\n",
    "\n",
    "\n",
    "Important: This code requires importing seaborn as sns and pandas. Our variable titanic holds a pandas DataFrame object. Know what imports are required for each bit of code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset from seaborn and verify\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a051d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null/NaN values\n",
    "null_count = titanic['embark_town'].isna().sum()\n",
    "print(f\"Number of null values in embark_town: {null_count}\")\n",
    "\n",
    "# Check for empty strings\n",
    "empty_string_count = (titanic['embark_town'] == '').sum()\n",
    "print(f\"Number of empty strings in embark_town: {empty_string_count}\")\n",
    "\n",
    "# Check for whitespace-only strings\n",
    "whitespace_count = (titanic['embark_town'].str.isspace()).sum()\n",
    "print(f\"Number of whitespace-only strings in embark_town: {whitespace_count}\")\n",
    "\n",
    "# Show rows with missing embark_town\n",
    "missing_embark = titanic[titanic['embark_town'].isna()]\n",
    "print(\"\\nRows with missing embark_town:\")\n",
    "print(missing_embark[['survived', 'pclass', 'sex', 'age', 'fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b29572",
   "metadata": {},
   "source": [
    "## Section 2. Data Exploration and Preparation\n",
    "\n",
    "Prepare the Titanic data for regression modeling. See the previous work.\n",
    "\n",
    "- Impute missing values for age using median\n",
    "- Drop rows with missing fare (or impute if preferred)\n",
    "- Create numeric variables (e.g., family_size from sibsp + parch + 1)\n",
    "- Optional - convert categorical features (e.g. sex, embarked) if you think they might help your prediction model. (We do not know relationships until we evaluate things.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of known ages\n",
    "age_mean = titanic['age'].mean()\n",
    "age_std = titanic['age'].std()\n",
    "\n",
    "# Count missing values\n",
    "age_null_count = titanic['age'].isnull().sum()\n",
    "\n",
    "# Generate random ages from normal distribution \n",
    "np.random.seed(307)  # For reproducibility\n",
    "age_random_values = np.random.normal(age_mean, age_std, age_null_count)\n",
    "\n",
    "# Apply age boundary constraints (0 to 85 years)\n",
    "age_random_values = np.clip(age_random_values, 0, 85)\n",
    "\n",
    "# Round ages to whole numbers\n",
    "age_random_values = np.round(age_random_values)\n",
    "\n",
    "# Create a mask for rows with missing age\n",
    "age_null_mask = titanic['age'].isnull()\n",
    "\n",
    "# Fill missing values with the random ages\n",
    "titanic.loc[age_null_mask, 'age'] = age_random_values\n",
    "\n",
    "# Round all ages in the dataset for consistency\n",
    "titanic['age'] = titanic['age'].round()\n",
    "\n",
    "# Verify no missing age values remain\n",
    "print(f\"Missing age values after imputation: {titanic['age'].isnull().sum()}\")\n",
    "\n",
    "titanic = titanic.dropna(subset=['fare'])\n",
    "\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94aaf30",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "Define multiple combinations of features to use as inputs to predict fare.\n",
    "\n",
    "Use unique names (X1, y1, X2, y2, etc.) so results are visible and can be compared at the same time. \n",
    "\n",
    "Remember the inputs, usually X, are a 2D array. The target is a 1D array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636950a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1. age\n",
    "X1 = titanic[['age']]\n",
    "y1 = titanic['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2. family_size\n",
    "X2 = titanic[['family_size']]\n",
    "y2 = titanic['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aae89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 3. age, family_size\n",
    "X3 = titanic[['age', 'family_size']]\n",
    "y3 = titanic['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beac5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 4. Embark_town\n",
    "\n",
    "# Converting embark_town and who to numeric values\n",
    "# First, make a copy to avoid warnings about modifying the DataFrame\n",
    "titanic_prep = titanic.copy()\n",
    "\n",
    "# Convert embark_town to numeric\n",
    "titanic_prep['embark_town_numeric'] = titanic_prep['embark_town'].map({\n",
    "    'Southampton': 0, \n",
    "    'Cherbourg': 1, \n",
    "    'Queenstown': 2\n",
    "})\n",
    "\n",
    "# Fill any NaN values that might result from the mapping\n",
    "titanic_prep['embark_town_numeric'] = titanic_prep['embark_town_numeric'].fillna(0)  # Default to Southampton\n",
    "# Case 4. embark_town and who (converted to numeric)\n",
    "\n",
    "X4 = titanic_prep[['embark_town_numeric']]\n",
    "y4 = titanic_prep['fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 5. pclass\n",
    "X5 = titanic[['pclass']]\n",
    "y5 = titanic['fare']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42133586",
   "metadata": {},
   "source": [
    "### Reflection Questions:\n",
    "\n",
    "#### Why might these features affect a passenger's fare:\n",
    "- Embarkation town could affect fare due to varying pricing at each port \n",
    "- Additionally, certain ports might have catered to wealthier clientbases\n",
    "\n",
    "#### List all available features:\n",
    "- survived, pclass, sex, age, sibsp, parch, fare, embarked, class, who, adult_male, deck, embark_town, alive, alone\n",
    "\n",
    "#### Which other features could improve predictions and why:\n",
    "Pclass would likely have the strongest effect as ticket class was the primary fare determinant. Deck could indicate premium accommodation pricing. Family size (sibsp + parch) might reveal group pricing patterns. Age could show different pricing tiers for adults vs. children. Sex might indicate if there were gender-based pricing differences in that era.\n",
    "\n",
    "#### How many variables are in your Case 4:\n",
    "One variable: embark_town_numeric\n",
    "\n",
    "#### Which variable(s) did you choose for Case 4 and why do you feel those could make good inputs:\n",
    "I chose embark_town because geographic location could significantly impact ticket pricing. Each port had different market conditions, operating costs, and possibly different pricing strategies. Queenstown, Southampton, and Cherbourg likely had different base fare structures. This variable allows the model to detect if location-based pricing was a significant factor independent of passenger class or demographic characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abeacd2",
   "metadata": {},
   "source": [
    "## Section 4. Train a Regression Model (Linear Regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97807223",
   "metadata": {},
   "source": [
    "### 4.1 Split the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=123)\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=123)\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=123)\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=123)\n",
    "\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cea6f6",
   "metadata": {},
   "source": [
    "### 4.2 Train and Evaluate Linear Regression Models (all 4 cases)\n",
    "\n",
    "\n",
    "We'll use a more concise approach - create each model and immediately call the fit() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model1 = LinearRegression().fit(X1_train, y1_train)\n",
    "lr_model2 = LinearRegression().fit(X2_train, y2_train)\n",
    "lr_model3 = LinearRegression().fit(X3_train, y3_train)\n",
    "lr_model4 = LinearRegression().fit(X4_train, y4_train)\n",
    "lr_model5 = LinearRegression().fit(X5_train, y5_train)\n",
    "\n",
    "\n",
    "# Predictions\n",
    "\n",
    "y_pred_train1 = lr_model1.predict(X1_train)\n",
    "y_pred_test1 = lr_model1.predict(X1_test)\n",
    "\n",
    "y_pred_train2 = lr_model2.predict(X2_train)\n",
    "y_pred_test2 = lr_model2.predict(X2_test)\n",
    "\n",
    "y_pred_train3 = lr_model3.predict(X3_train)\n",
    "y_pred_test3 = lr_model3.predict(X3_test)\n",
    "\n",
    "y_pred_train4 = lr_model4.predict(X4_train)\n",
    "y_pred_test4 = lr_model4.predict(X4_test)\n",
    "\n",
    "y_pred_train5 = lr_model5.predict(X5_train)\n",
    "y_pred_test5 = lr_model5.predict(X5_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a13217",
   "metadata": {},
   "source": [
    "### 4.3 Report Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6dbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 1 Performance\n",
    "print(\"Case 1: Training R²:\", r2_score(y1_train, y_pred_train1))\n",
    "print(\"Case 1: Test R²:\", r2_score(y1_test, y_pred_test1))\n",
    "print(\"Case 1: Test RMSE:\", root_mean_squared_error(y1_test, y_pred_test1))\n",
    "print(\"Case 1: Test MAE:\", mean_absolute_error(y1_test, y_pred_test1))\n",
    "\n",
    "# Case 2 Performance\n",
    "print(\"Case 2: Training R²:\", r2_score(y2_train, y_pred_train2))\n",
    "print(\"Case 2: Test R²:\", r2_score(y2_test, y_pred_test2))\n",
    "print(\"Case 2: Test RMSE:\", root_mean_squared_error(y2_test, y_pred_test2))\n",
    "print(\"Case 2: Test MAE:\", mean_absolute_error(y2_test, y_pred_test2))\n",
    "\n",
    "# Case 3 Performance\n",
    "print(\"Case 3: Training R²:\", r2_score(y3_train, y_pred_train3))\n",
    "print(\"Case 3: Test R²:\", r2_score(y3_test, y_pred_test3))\n",
    "print(\"Case 3: Test RMSE:\", root_mean_squared_error(y3_test, y_pred_test3))\n",
    "print(\"Case 3: Test MAE:\", mean_absolute_error(y3_test, y_pred_test3))\n",
    "\n",
    "# Case 4 Performance\n",
    "print(\"Case 4: Training R²:\", r2_score(y4_train, y_pred_train4))\n",
    "print(\"Case 4: Test R²:\", r2_score(y4_test, y_pred_test4))\n",
    "print(\"Case 4: Test RMSE:\", root_mean_squared_error(y4_test, y_pred_test4))\n",
    "print(\"Case 4: Test MAE:\", mean_absolute_error(y4_test, y_pred_test4))\n",
    "\n",
    "# Case 5 Performance\n",
    "print(\"Case 5: Training R²:\", r2_score(y5_train, y_pred_train5))\n",
    "print(\"Case 5: Test R²:\", r2_score(y5_test, y_pred_test5))\n",
    "print(\"Case 5: Test RMSE:\", root_mean_squared_error(y5_test, y_pred_test5))\n",
    "print(\"Case 5: Test MAE:\", mean_absolute_error(y5_test, y_pred_test5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46101bc2",
   "metadata": {},
   "source": [
    "### Section 4 Reflection Questions\n",
    "\n",
    "#### Compare the train vs test results for each.\n",
    "\n",
    "While I did answer the questions for cases 1-4, it's worth saying that with extremely low R² values, the concepts of overfitting and underfitting become somewhat meaningless. For a model to meaningfully overfit or underfit, there should be an actual pattern in the data that can be captured. When R² values are near zero (like 0.005 or 0.05), they indicate that essentially no relationship exists between the predictors and the target variable.\n",
    "\n",
    "1. **Did Case 1 overfit or underfit? Explain:**\n",
    "   Age -  underfit. Both training R² (0.0061) and test R² (0.0055) are extremely low and similar, indicating the model failed to capture meaningful patterns between age and fare.\n",
    "\n",
    "2. **Did Case 2 overfit or underfit? Explain:**\n",
    "   family_size - showed slight overfitting. The training R² (0.0499) is more than double the test R² (0.0222), indicating the model learned patterns in training data that didn't generalize well to test data. Still, both values are very low.\n",
    "\n",
    "3. **Did Case 3 overfit or underfit? Explain:**\n",
    "   age and family_size - showed slight overfitting as the training R² (0.0662) is higher than the test R² (0.0487). This captured more information than the first two cases, but still explains less than 5% of fare variance.\n",
    "\n",
    "4. **Did Case 4 overfit or underfit? Explain:**\n",
    "   embark_town - likely underfit, though it shows unusual behavior with test R² (0.0085) higher than training R² (0.0031). Both values are extremely low, indicating the model failed to capture meaningful patterns. The reversed R² values suggest random variation in the data split rather than a true pattern.\n",
    "\n",
    "5. **Did Case 5 overfit or underfit? Explain:**\n",
    "   pclass - showed balanced fitting. I included it as a bonus sanity test since the correlations were so low on the other cases. The training R² (0.301) and test R² (0.302) are virtually identical, indicating good generalization. This model explains about 30% of fare variance, significantly better than all other cases.\n",
    "\n",
    "\n",
    "#### Adding Age\n",
    "\n",
    "1. **Did adding age improve the model:**\n",
    "   Yes, infinitesmally. Comparing Case 2 (family_size only, R²=0.022) to Case 3 (age and family_size, R²=0.049), adding age did double the test R² and reduced MAE from 25.03 to 24.13...but despite that, the correlation generally remained very low.\n",
    "\n",
    "2. **Propose a possible explanation:**\n",
    "   Age might effect ticket price because: (1) different fare structures may have existed for children vs. adults, (2) age may correlate with wealth or social status that influenced cabin class selection, or (3) families with young children might have required different accommodations. However, the low R² values suggest this relationship is still quite weak compared to other factors like passenger class.\n",
    "\n",
    "\n",
    "#### Worst\n",
    "\n",
    "1. **Which case performed the worst:**\n",
    "   Case 1 - age\n",
    "\n",
    "2. **How do you know:**\n",
    "   It has the lowest test R² (0.0055), and the highest RMSE [37.93].\n",
    "\n",
    "3. **Do you think adding more training data would improve it (and why/why not):**\n",
    "   No. The problem isn't insufficient data, but that age alone has almost no relationship with fare (R² near zero). More data with the same weak predictor probably wouldn't improve performance.\n",
    "   \n",
    "\n",
    "#### Best\n",
    "\n",
    "1. **Which case performed the best:**\n",
    "   Case 5  - pclass\n",
    "\n",
    "2. **How do you know:**\n",
    "   It has much higher test R² (0.302) than the others. It also has the lowest RMSE (31.79) and MAE (20.65), indicating more accurate predictions.\n",
    "\n",
    "3. **Do you think adding more training data would improve it (and why/why not):**\n",
    "   No, I think not. The model already shows consistent generalization, nearly identical between train and test R². However adding different features like deck or combining with other features might likely yield better improvements than more training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8c753",
   "metadata": {},
   "source": [
    "## Section 5. Compare Alternative Models\n",
    "In this section, we will take the best-performing case and explore other regression models.\n",
    "\n",
    "Choose Best Case to Continue\n",
    "Choose the best case model from the four cases. Use that model to continue to explore additional continuous prediction models. The following assumes that Case 1 was the best predictor  - this may not be the case. Adjust the code to use your best case model instead. \n",
    "\n",
    "Choosing Options\n",
    "When working with regression models, especially those with multiple input features, we may run into overfitting — where a model fits the training data too closely and performs poorly on new data. To prevent this, we can apply regularization.\n",
    "\n",
    "Regularization adds a penalty to the model’s loss function, discouraging it from using very large weights (coefficients). This makes the model simpler and more likely to generalize well to new data.\n",
    "\n",
    "In general: \n",
    "\n",
    "If the basic linear regression is overfitting, try Ridge.\n",
    "\n",
    "If you want the model to automatically select the most important features, try Lasso.\n",
    "\n",
    "If you want a balanced approach, try Elastic Net."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426f204",
   "metadata": {},
   "source": [
    "### 5.1 Ridge Regression (L2 penalty)\n",
    "Ridge Regression is a regularized version of linear regression that adds a penalty to large coefficient values. It uses the L2 penalty, which adds the sum of squared coefficients to the loss function.\n",
    "\n",
    "This \"shrinks\" the coefficients, reducing the model’s sensitivity to any one feature while still keeping all features in the model.\n",
    "\n",
    "Penalty term: L2 = sum of squared weights\n",
    "Effect: Shrinks weights, helps reduce overfitting, keeps all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X1_train, y1_train)\n",
    "y_pred_ridge = ridge_model.predict(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b7929b",
   "metadata": {},
   "source": [
    "### 5.2 Elastic Net (L1 + L2 combined)\n",
    "Lasso Regression uses the L1 penalty, which adds the sum of absolute values of the coefficients to the loss function. Lasso can shrink some coefficients all the way to zero, effectively removing less important features. This makes it useful for feature selection.\n",
    "\n",
    "Penalty term: L1 = sum of absolute values of weights\n",
    "Effect: Can shrink some weights to zero (drops features), simplifies the model\n",
    "Elastic Net combines both L1 (Lasso) and L2 (Ridge) penalties. It balances the feature selection ability of Lasso with the stability of Ridge.\n",
    "\n",
    "We control the balance with a parameter called l1_ratio:\n",
    "\n",
    "If l1_ratio = 0, it behaves like Ridge\n",
    "If l1_ratio = 1, it behaves like Lasso\n",
    "Values in between mix both types\n",
    "Penalty term: α × (L1 + L2)\n",
    "Effect: Shrinks weights and can drop some features — flexible and powerful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d875cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_model = ElasticNet(alpha=0.3, l1_ratio=0.5)\n",
    "elastic_model.fit(X1_train, y1_train)\n",
    "y_pred_elastic = elastic_model.predict(X1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36deda3",
   "metadata": {},
   "source": [
    "### 5.3 Polynomial Regression\n",
    "Linear regression is a simple two dimensional relationship - a simple straight line. But we can test more complex relationships. Polynomial regression adds interaction and nonlinear terms to the model. Be careful here - higher-degree polynomials can easily overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the poly inputs\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "X_train_poly = poly.fit_transform(X1_train)\n",
    "X1_test_poly = poly.transform(X1_test)\n",
    " \n",
    "\n",
    "# Use the poly inputs in the LR model\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y1_train)\n",
    "y_pred_poly = poly_model.predict(X1_test_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e95eec",
   "metadata": {},
   "source": [
    "### 5.4 Visualize Polynomial Cubic Fit (for 1 input feature)\n",
    "Choose a case with just one input feature and plot it. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X1_test, y1_test, color='blue', label='Actual')\n",
    "plt.scatter(X1_test, y_pred_poly, color='red', label='Predicted (Poly)')\n",
    "plt.legend()\n",
    "plt.title(\"Polynomial Regression: Age vs Fare\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260854f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(name, y_true, y_pred):\n",
    "    print(f\"{name} R²: {r2_score(y_true, y_pred):.3f}\")\n",
    "    print(f\"{name} RMSE: {root_mean_squared_error(y_true, y_pred):.2f}\")\n",
    "    print(f\"{name} MAE: {mean_absolute_error(y_true, y_pred):.2f}\\n\")\n",
    "\n",
    "report(\"Linear\", y1_test, y_pred_test1)\n",
    "report(\"Ridge\", y1_test, y_pred_ridge)\n",
    "report(\"ElasticNet\", y1_test, y_pred_elastic)\n",
    "report(\"Polynomial\", y1_test, y_pred_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb26d00",
   "metadata": {},
   "source": [
    "## 5.5 Visualize Higher Order Polynomial (for the same 1 input case)\n",
    "\n",
    "Use the same single input case as you visualized above, but use a higher degree polynomial (e.g. 4, 5, 6, 7, or 8). Plot the result. \n",
    "\n",
    "In a Markdown cell, tell us which option seems to work better - your initial cubic (3) or your higher order and why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing multiple polynomial degrees\n",
    "degrees = [3, 4, 6, 8]\n",
    "poly_models = {}\n",
    "y_preds = {}\n",
    "r2_scores = {}\n",
    "\n",
    "# Train models for each degree\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly_transformer = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly_deg = poly_transformer.fit_transform(X1_train)\n",
    "    X_test_poly_deg = poly_transformer.transform(X1_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly_deg, y1_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(X_test_poly_deg)\n",
    "    \n",
    "    # Store results\n",
    "    poly_models[degree] = model\n",
    "    y_preds[degree] = y_pred\n",
    "    r2_scores[degree] = r2_score(y1_test, y_pred)\n",
    "\n",
    "# Create plots for each degree\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, degree in enumerate(degrees, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.scatter(X1_test, y1_test, color='blue', alpha=0.6, label='Actual')\n",
    "    plt.scatter(X1_test, y_preds[degree], color=f'C{i}', alpha=0.6, label=f'Degree {degree}')\n",
    "    \n",
    "    # To visualize the curve better, let's sort the points by x-value\n",
    "    sorted_indices = X1_test.iloc[:, 0].argsort()\n",
    "    sorted_X = X1_test.iloc[sorted_indices]\n",
    "    sorted_y_pred = y_preds[degree][sorted_indices]\n",
    "    \n",
    "    # Draw a line connecting predictions\n",
    "    plt.plot(sorted_X, sorted_y_pred, color=f'C{i}', linestyle='-', alpha=0.7)\n",
    "    \n",
    "    plt.title(f\"Polynomial Regression (Degree {degree}): Age vs Fare\")\n",
    "    plt.xlabel(\"Age\")\n",
    "    plt.ylabel(\"Fare\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Add R² value to plot\n",
    "    plt.annotate(f\"R² = {r2_scores[degree]:.4f}\", \n",
    "                 xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Report performance metrics for each model\n",
    "print(\"Performance Metrics for Different Polynomial Degrees:\\n\")\n",
    "for degree in degrees:\n",
    "    print(f\"Polynomial Degree {degree}:\")\n",
    "    print(f\"R²: {r2_scores[degree]:.4f}\")\n",
    "    print(f\"RMSE: {root_mean_squared_error(y1_test, y_preds[degree]):.2f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y1_test, y_preds[degree]):.2f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing multiple polynomial degrees using pclass as the input feature\n",
    "degrees = [3, 4, 6, 8]\n",
    "poly_models_pclass = {}\n",
    "y_preds_pclass = {}\n",
    "r2_scores_pclass = {}\n",
    "\n",
    "# Train models for each degree\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly_transformer = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly_deg = poly_transformer.fit_transform(X5_train)  # Using X5 (pclass) instead of X1 (age)\n",
    "    X_test_poly_deg = poly_transformer.transform(X5_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly_deg, y5_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(X_test_poly_deg)\n",
    "    \n",
    "    # Store results\n",
    "    poly_models_pclass[degree] = model\n",
    "    y_preds_pclass[degree] = y_pred\n",
    "    r2_scores_pclass[degree] = r2_score(y5_test, y_pred)\n",
    "\n",
    "# Create plots for each degree\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, degree in enumerate(degrees, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.scatter(X5_test, y5_test, color='blue', alpha=0.6, label='Actual')\n",
    "    plt.scatter(X5_test, y_preds_pclass[degree], color=f'C{i}', alpha=0.6, label=f'Degree {degree}')\n",
    "    \n",
    "    # Create sorted data for a cleaner line plot\n",
    "    sorted_indices = X5_test.iloc[:, 0].argsort()\n",
    "    sorted_X = X5_test.iloc[sorted_indices]\n",
    "    sorted_y_pred = y_preds_pclass[degree][sorted_indices]\n",
    "    \n",
    "    # Draw a line connecting predictions\n",
    "    plt.plot(sorted_X, sorted_y_pred, color=f'C{i}', linestyle='-', alpha=0.7)\n",
    "    \n",
    "    plt.title(f\"Polynomial Regression (Degree {degree}): Pclass vs Fare\")\n",
    "    plt.xlabel(\"Passenger Class\")\n",
    "    plt.ylabel(\"Fare\")\n",
    "    plt.legend()\n",
    "    plt.xticks([1, 2, 3], ['First', 'Second', 'Third'])\n",
    "    \n",
    "    # Add R² value to plot\n",
    "    plt.annotate(f\"R² = {r2_scores_pclass[degree]:.4f}\", \n",
    "                 xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Report performance metrics for each model\n",
    "print(\"Performance Metrics for Different Polynomial Degrees (Pclass):\\n\")\n",
    "for degree in degrees:\n",
    "    print(f\"Polynomial Degree {degree}:\")\n",
    "    print(f\"R²: {r2_scores_pclass[degree]:.4f}\")\n",
    "    print(f\"RMSE: {root_mean_squared_error(y5_test, y_preds_pclass[degree]):.2f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y5_test, y_preds_pclass[degree]):.2f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84c906f",
   "metadata": {},
   "source": [
    "R^2 values are good compared to other cases, but clearly changing the degree makes no difference and the visualizations are unclear. Let's try combining with P-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined feature set with pclass and family_size\n",
    "X_combined = titanic[['pclass', 'family_size']]\n",
    "\n",
    "# Split the data\n",
    "X_combined_train, X_combined_test, y_combined_train, y_combined_test = train_test_split(\n",
    "    X_combined, titanic['fare'], test_size=0.2, random_state=123)\n",
    "\n",
    "# Train a linear regression model\n",
    "lr_combined = LinearRegression()\n",
    "lr_combined.fit(X_combined_train, y_combined_train)\n",
    "y_pred_combined = lr_combined.predict(X_combined_test)\n",
    "\n",
    "# Create a 3D visualization of the multi-feature regression\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the actual data points\n",
    "ax.scatter(X_combined_test['pclass'], X_combined_test['family_size'], y_combined_test, \n",
    "           color='blue', alpha=0.6, marker='o', s=40, label='Actual')\n",
    "\n",
    "# Plot predicted data points\n",
    "ax.scatter(X_combined_test['pclass'], X_combined_test['family_size'], y_pred_combined, \n",
    "           color='red', alpha=0.6, marker='^', s=40, label='Predicted')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Passenger Class')\n",
    "ax.set_ylabel('Family Size')\n",
    "ax.set_zlabel('Fare')\n",
    "ax.set_title('Linear Regression: Pclass & Family Size vs Fare')\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_xticklabels(['First', 'Second', 'Third'])\n",
    "\n",
    "# Set a lower viewing angle\n",
    "ax.view_init(elev=20, azim=-35)  # Lower elevation, adjust azimuth\n",
    "\n",
    "# Add R² value to plot\n",
    "ax.text2D(0.05, 0.95, f\"R² = {r2_score(y_combined_test, y_pred_combined):.4f}\", \n",
    "         transform=ax.transAxes,\n",
    "         bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "# Make legend more visible\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1, 0.9), fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3ad203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing multiple polynomial degrees with combined features\n",
    "degrees = [3, 4, 6, 8]\n",
    "poly_models_combined = {}\n",
    "y_preds_combined = {}\n",
    "r2_scores_combined = {}\n",
    "\n",
    "# Define distinct colors for better contrast\n",
    "colors = ['orange', 'green', 'purple', 'red']\n",
    "\n",
    "# Train models for each degree\n",
    "for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly_transformer = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly_deg = poly_transformer.fit_transform(X_combined_train)\n",
    "    X_test_poly_deg = poly_transformer.transform(X_combined_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly_deg, y_combined_train)\n",
    "    \n",
    "    # Generate predictions\n",
    "    y_pred = model.predict(X_test_poly_deg)\n",
    "    \n",
    "    # Store results\n",
    "    poly_models_combined[degree] = model\n",
    "    y_preds_combined[degree] = y_pred\n",
    "    r2_scores_combined[degree] = r2_score(y_combined_test, y_pred)\n",
    "\n",
    "# Create plots for each degree using 3D visualization\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for i, degree in enumerate(degrees):\n",
    "    # Create 3D subplot\n",
    "    ax = plt.subplot(2, 2, i+1, projection='3d')\n",
    "    \n",
    "    # Plot actual data points\n",
    "    ax.scatter(X_combined_test['pclass'], X_combined_test['family_size'], y_combined_test, \n",
    "               color='blue', alpha=0.5, marker='o', s=30, label='Actual')\n",
    "    \n",
    "    # Plot predicted data points\n",
    "    ax.scatter(X_combined_test['pclass'], X_combined_test['family_size'], y_preds_combined[degree], \n",
    "               color=colors[i], alpha=0.7, marker='^', s=40, label=f'Degree {degree}')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Passenger Class')\n",
    "    ax.set_ylabel('Family Size')\n",
    "    ax.set_zlabel('Fare')\n",
    "    ax.set_title(f\"Polynomial (Degree {degree}): Pclass & Family Size vs Fare\")\n",
    "    ax.set_xticks([1, 2, 3])\n",
    "    ax.set_xticklabels(['First', 'Second', 'Third'])\n",
    "    \n",
    "    # Set a lower viewing angle\n",
    "    ax.view_init(elev=20, azim=-35)  # Lower elevation, adjust azimuth\n",
    "    \n",
    "    # Add R² value to plot\n",
    "    ax.text2D(0.05, 0.95, f\"R² = {r2_scores_combined[degree]:.4f}\", \n",
    "             transform=ax.transAxes,\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.15, hspace=0.2)  # Adjust spacing\n",
    "plt.show()\n",
    "\n",
    "# Report performance metrics for each model\n",
    "print(\"Performance Metrics for Different Polynomial Degrees (Combined Features):\\n\")\n",
    "for i, degree in enumerate(degrees):\n",
    "    print(f\"Polynomial Degree {degree} ({colors[i]}):\")\n",
    "    print(f\"R²: {r2_scores_combined[degree]:.4f}\")\n",
    "    print(f\"RMSE: {root_mean_squared_error(y_combined_test, y_preds_combined[degree]):.2f}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_combined_test, y_preds_combined[degree]):.2f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4aa1b",
   "metadata": {},
   "source": [
    "Yes, the decreasing R² value as the polynomial degree increases (from degree 4 to degrees 6 and 8) is indeed a classic sign of overfitting. Here's what's happening:\n",
    "\n",
    "With degree 4 (R² = 0.5187), the model has found a good balance between complexity and generalization. It captures the underlying patterns in the data without fitting to noise.\n",
    "As we increase to degree 6 (R² = 0.5025), the model becomes more complex but actually performs worse on test data. This suggests it's starting to fit to random fluctuations in the training data.\n",
    "By degree 8 (R² = 0.4912), the overfitting is even more pronounced, with further decreased performance.\n",
    "\n",
    "This pattern is a textbook example of the bias-variance tradeoff in machine learning:\n",
    "\n",
    "Too simple (low degree): high bias, underfitting\n",
    "Good balance (degree 4): captures real patterns\n",
    "Too complex (higher degrees): high variance, overfitting\n",
    "\n",
    "This is why it's generally good practice to try multiple model complexities and select the one that performs best on validation/test data rather than just assuming that more complexity will always yield better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb704de9",
   "metadata": {},
   "source": [
    "Section 6. Final Thoughts & Insights\n",
    "Your notebook should tell a data story. Use this section to demonstrate your thinking and value as an analyst.\n",
    "\n",
    "6.1 Summarize Findings\n",
    "What features were most useful?\n",
    "\n",
    "What regression model performed best?\n",
    "\n",
    "How did model complexity or regularization affect results?\n",
    "\n",
    " \n",
    "\n",
    "6.2 Discuss Challenges\n",
    "Was fare hard to predict? Why?\n",
    "\n",
    "Did skew or outliers impact the models?\n",
    "\n",
    " \n",
    "\n",
    "6.3 Optional Next Steps\n",
    "Try different features besides the ones used (e.g., pclass, sex if you didn't use them this time)\n",
    "\n",
    "Try predicting age instead of fare\n",
    "\n",
    "Explore log transformation of fare to reduce skew\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
